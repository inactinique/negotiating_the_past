{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncks0uTDzzbr"
      },
      "source": [
        "# negotiating the past"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAMm3ta9zzbt"
      },
      "source": [
        "To install the environment, see README.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDuaGCSnzzb0"
      },
      "source": [
        "## setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmRnFRyxzzb1"
      },
      "source": [
        "We load the necessary libraries. If using colab, you might want to restart your kernel afterwards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrCaiB6xzzb1",
        "outputId": "117d6fe6-6471-4c64-e895-be913cfab48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.11\n",
            "Requirement already satisfied: umap-learn in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (0.5.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from umap-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from umap-learn) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from umap-learn) (0.61.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.6.0)\n",
            "Requirement already satisfied: gensim in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: nltk in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (3.9.1)\n",
            "Requirement already satisfied: click in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/negotiating_past/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python --version\n",
        "!pip install umap-learn\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vtFna26EPTe",
        "outputId": "d05f3874-d6be-4a64-fc3a-947b35b694a9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we mount google drive. Skip if you're not using google drive\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      4\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# we mount google drive. Skip if you're not using google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaKgggqHzzb2"
      },
      "source": [
        "## Creating a Historical Prompt Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX5tD0evzzb3",
        "outputId": "e8c41167-e48f-42e8-c498-dc51f2870cd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Loading the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import ssl\n",
        "\n",
        "# Make sure you have the necessary NLTK resources\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Read the CSV file -- we load only 10 000 rows and the first column for this dataset of prompts.\n",
        "prompts_df = pd.read_csv(\"drive/MyDrive/data/prompts.csv\", on_bad_lines='skip', nrows=1000, usecols=[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWV0Mqlazzb3"
      },
      "source": [
        "## Historical Reference Detection Approach With DistilBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWAtuQpchZ_W"
      },
      "source": [
        "### Set up the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7kCiBnizzb3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from umap import UMAP\n",
        "from sklearn.cluster import DBSCAN\n",
        "from tqdm import tqdm  # Pour les barres de progression\n",
        "import gc  # Nettoyage de m√©moire\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# D√©finir le nombre de c≈ìurs CPU √† utiliser\n",
        "num_cpu_cores = 8\n",
        "torch.set_num_threads(num_cpu_cores)\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(num_cpu_cores)\n",
        "os.environ[\"MKL_NUM_THREADS\"] = str(num_cpu_cores)\n",
        "\n",
        "def improved_historical_identification(prompts_df, sample_size=1000):\n",
        "    \"\"\"\n",
        "    Version am√©lior√©e de l'identification des prompts historiques\n",
        "    \"\"\"\n",
        "    # √âchantillonnage si n√©cessaire\n",
        "    if len(prompts_df) > sample_size:\n",
        "        sample_df = prompts_df.sample(sample_size, random_state=42)\n",
        "        print(f\"√âchantillonnage de {sample_size} prompts sur {len(prompts_df)} au total\")\n",
        "    else:\n",
        "        sample_df = prompts_df.copy()\n",
        "        print(f\"Traitement de tous les {len(sample_df)} prompts\")\n",
        "\n",
        "    # Nettoyage m√©moire\n",
        "    gc.collect()\n",
        "\n",
        "    # Liste des prompts avec filtrage des valeurs non valides\n",
        "    prompts_list = sample_df['prompt'].fillna('').tolist()\n",
        "    valid_text_mask = [isinstance(text, str) and bool(text.strip()) for text in prompts_list]\n",
        "    valid_prompts = [text for i, text in enumerate(prompts_list) if valid_text_mask[i]]\n",
        "\n",
        "    print(f\"Prompts valides : {len(valid_prompts)} sur {len(prompts_list)}\")\n",
        "\n",
        "    # Filtrer le DataFrame pour ne conserver que les lignes avec texte valide\n",
        "    sample_df = sample_df[valid_text_mask].reset_index(drop=True)\n",
        "\n",
        "    # G√©n√©ration des embeddings\n",
        "    print(\"G√©n√©ration des embeddings des prompts...\")\n",
        "    print(\"Chargement du mod√®le SentenceTransformer...\")\n",
        "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "    # Traitement par lots pour √©conomiser la m√©moire\n",
        "    batch_size = 32\n",
        "    prompt_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(valid_prompts), batch_size), desc=\"G√©n√©ration des embeddings\"):\n",
        "        batch = valid_prompts[i:i+batch_size]\n",
        "        batch_embeddings = model.encode(batch, show_progress_bar=False)\n",
        "        prompt_embeddings.append(batch_embeddings)\n",
        "\n",
        "    prompt_embeddings = np.vstack(prompt_embeddings)\n",
        "\n",
        "    # V√©rifier que la longueur correspond\n",
        "    assert len(sample_df) == prompt_embeddings.shape[0], \"Incoh√©rence entre la longueur du DataFrame et des embeddings\"\n",
        "\n",
        "    # D√©finir des concepts historiques plus diversifi√©s\n",
        "    historical_concepts = [\n",
        "        # P√©riodes historiques explicites\n",
        "        \"ancient history\", \"medieval times\", \"renaissance period\",\n",
        "        \"world war\", \"cold war\", \"industrial revolution\", \"prehistoric era\",\n",
        "\n",
        "        # Termes plus g√©n√©raux et implicites\n",
        "        \"history\", \"historical event\", \"in the past\", \"ancient times\",\n",
        "        \"vintage\", \"retro\", \"old fashioned\", \"traditional\",\n",
        "\n",
        "        # Styles et esth√©tiques historiques\n",
        "        \"victorian style\", \"art deco\", \"baroque\", \"gothic\", \"classical\",\n",
        "        \"midcentury\", \"ancient greek\", \"roman empire\", \"medieval knight\",\n",
        "\n",
        "        # R√©f√©rences √† la culture populaire historique\n",
        "        \"steampunk\", \"dieselpunk\", \"historical fiction\", \"period drama\",\n",
        "        \"historical costume\", \"historical setting\"\n",
        "    ]\n",
        "\n",
        "    # G√©n√©rer des embeddings pour les concepts historiques\n",
        "    print(\"G√©n√©ration des embeddings de concepts historiques...\")\n",
        "    historical_embeddings = model.encode(historical_concepts)\n",
        "\n",
        "    # Nettoyer la m√©moire\n",
        "    gc.collect()\n",
        "\n",
        "    # Calculer la similarit√© pour chaque concept\n",
        "    print(\"Calcul des similarit√©s...\")\n",
        "    concept_similarities = np.zeros((len(valid_prompts), len(historical_concepts)))\n",
        "\n",
        "    for i in tqdm(range(0, len(valid_prompts), batch_size), desc=\"Calcul par lots\"):\n",
        "        end_idx = min(i + batch_size, len(valid_prompts))\n",
        "        batch_embeddings = prompt_embeddings[i:end_idx]\n",
        "\n",
        "        for j in range(len(historical_concepts)):\n",
        "            concept_similarities[i:end_idx, j] = cosine_similarity(\n",
        "                batch_embeddings,\n",
        "                historical_embeddings[j].reshape(1, -1)\n",
        "            ).flatten()\n",
        "\n",
        "    # Pour chaque prompt, trouver le concept le plus similaire\n",
        "    max_similarity_indices = np.argmax(concept_similarities, axis=1)\n",
        "    max_similarities = np.max(concept_similarities, axis=1)\n",
        "\n",
        "    # Attribuer des seuils diff√©rents selon les cat√©gories de concepts\n",
        "    concept_thresholds = {\n",
        "        # Seuils plus √©lev√©s pour termes explicites\n",
        "        \"ancient history\": 0.5,\n",
        "        \"medieval times\": 0.5,\n",
        "        \"renaissance period\": 0.5,\n",
        "        \"world war\": 0.5,\n",
        "        \"cold war\": 0.5,\n",
        "        \"industrial revolution\": 0.5,\n",
        "\n",
        "        # Seuils plus bas pour termes implicites ou g√©n√©raux\n",
        "        \"history\": 0.45,\n",
        "        \"historical event\": 0.45,\n",
        "        \"in the past\": 0.4,\n",
        "        \"ancient times\": 0.45,\n",
        "\n",
        "        # Seuils interm√©diaires pour styles\n",
        "        \"victorian style\": 0.48,\n",
        "        \"art deco\": 0.48,\n",
        "        \"baroque\": 0.48,\n",
        "    }\n",
        "\n",
        "    # Seuil par d√©faut pour les concepts non list√©s sp√©cifiquement\n",
        "    default_threshold = 0.45\n",
        "\n",
        "    # V√©rifier si chaque prompt d√©passe le seuil pour son concept le plus similaire\n",
        "    is_historical = []\n",
        "    for i, (max_sim, concept_idx) in enumerate(zip(max_similarities, max_similarity_indices)):\n",
        "        concept = historical_concepts[concept_idx]\n",
        "        threshold = concept_thresholds.get(concept, default_threshold)\n",
        "        is_historical.append(max_sim > threshold)\n",
        "\n",
        "    # Convertir en array numpy pour faciliter l'indexation\n",
        "    is_historical = np.array(is_historical)\n",
        "\n",
        "    # Ajouter les r√©sultats au DataFrame\n",
        "    sample_df['most_similar_concept'] = [historical_concepts[idx] for idx in max_similarity_indices]\n",
        "    sample_df['similarity_score'] = max_similarities\n",
        "    sample_df['is_historical'] = is_historical\n",
        "\n",
        "    # Filtrer les prompts historiques\n",
        "    historical_prompts = sample_df[is_historical].copy()\n",
        "\n",
        "    print(f\"Identification de {len(historical_prompts)} prompts historiques ({len(historical_prompts)/len(sample_df):.2%} de l'√©chantillon)\")\n",
        "\n",
        "    # M√©thode hybride - combiner embeddings et mots-cl√©s pour am√©liorer la couverture\n",
        "    keywords = [\n",
        "        \"history\", \"ancient\", \"medieval\", \"renaissance\", \"century\",\n",
        "        \"war\", \"empire\", \"kingdom\", \"historical\", \"vintage\", \"retro\",\n",
        "        \"traditional\", \"old\", \"classical\", \"antique\"\n",
        "    ]\n",
        "\n",
        "    keyword_mask = sample_df['prompt'].fillna('').str.lower().str.contains('|'.join(keywords))\n",
        "    missed_by_embedding = sample_df[~is_historical & keyword_mask].copy()\n",
        "    missed_by_embedding['detection_method'] = 'keyword_only'\n",
        "\n",
        "    # Ajouter un marqueur pour les prompts d√©tect√©s par embedding\n",
        "    historical_prompts['detection_method'] = 'embedding'\n",
        "\n",
        "    # Fusionner les deux ensembles\n",
        "    combined_historical = pd.concat([historical_prompts, missed_by_embedding], ignore_index=True)\n",
        "\n",
        "    print(f\"Identification suppl√©mentaire de {len(missed_by_embedding)} prompts par mots-cl√©s\")\n",
        "    print(f\"Total de prompts historiques: {len(combined_historical)} ({len(combined_historical)/len(sample_df):.2%} de l'√©chantillon)\")\n",
        "\n",
        "    return combined_historical, prompt_embeddings, is_historical\n",
        "\n",
        "def analyze_historical_clusters(historical_prompts, prompt_embeddings, is_historical):\n",
        "    \"\"\"\n",
        "    Version adapt√©e pour fonctionner avec la nouvelle m√©thode d'identification\n",
        "    \"\"\"\n",
        "    if len(historical_prompts) > 10:  # Besoin d'un minimum d'√©chantillons pour le clustering\n",
        "        # S√©lectionner les embeddings des prompts historiques identifi√©s par embedding\n",
        "        embedding_historical = historical_prompts[historical_prompts['detection_method'] == 'embedding']\n",
        "\n",
        "        # Cr√©er un masque pour extraire les embeddings appropri√©s\n",
        "        # Note: Cette approche suppose que les indices des historical_prompts correspondent\n",
        "        # aux indices filtr√©s dans prompt_embeddings\n",
        "        historical_indices = embedding_historical.index\n",
        "        historical_embeddings = prompt_embeddings[historical_indices]\n",
        "\n",
        "        print(\"Application de la r√©duction dimensionnelle UMAP...\")\n",
        "        # Appliquer UMAP avec optimisation CPU\n",
        "        umap_model = UMAP(n_neighbors=15, min_dist=0.1, random_state=42,\n",
        "                          n_jobs=num_cpu_cores)\n",
        "        historical_umap = umap_model.fit_transform(historical_embeddings)\n",
        "\n",
        "        print(\"Clustering avec DBSCAN...\")\n",
        "        # Appliquer DBSCAN\n",
        "        dbscan = DBSCAN(eps=0.5, min_samples=5, n_jobs=num_cpu_cores)\n",
        "        cluster_labels = dbscan.fit_predict(historical_umap)\n",
        "\n",
        "        # Ajouter les √©tiquettes de cluster au DataFrame, uniquement pour les prompts d√©tect√©s par embedding\n",
        "        # Initialiser une colonne de cluster avec des valeurs NaN\n",
        "        historical_prompts['cluster'] = float('nan')\n",
        "\n",
        "        # Mettre √† jour les valeurs de cluster pour les prompts d√©tect√©s par embedding\n",
        "        idx_map = {old_idx: new_idx for new_idx, old_idx in enumerate(historical_indices)}\n",
        "        for i, idx in enumerate(historical_indices):\n",
        "            historical_prompts.loc[idx, 'cluster'] = cluster_labels[i]\n",
        "\n",
        "        # G√©n√©rer rapport et visualisations, uniquement pour les prompts avec clusters\n",
        "        generate_cluster_report(embedding_historical, historical_umap, cluster_labels)\n",
        "\n",
        "        return historical_prompts, historical_umap, cluster_labels\n",
        "    else:\n",
        "        print(\"Pas assez de prompts historiques pour le clustering\")\n",
        "        return historical_prompts, None, None\n",
        "\n",
        "def generate_cluster_report(historical_prompts, historical_umap, cluster_labels):\n",
        "    # Nombre de prompts par cluster\n",
        "    cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
        "    print(\"\\nNombre de prompts par cluster:\")\n",
        "    print(cluster_counts)\n",
        "\n",
        "    # Visualiser les clusters\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    # Exclure les points de bruit (cluster -1) pour une meilleure visualisation\n",
        "    non_noise_mask = cluster_labels != -1\n",
        "\n",
        "    if np.any(non_noise_mask):  # V√©rifier qu'il y a des points non-bruit\n",
        "        scatter = plt.scatter(\n",
        "            historical_umap[non_noise_mask, 0],\n",
        "            historical_umap[non_noise_mask, 1],\n",
        "            c=cluster_labels[non_noise_mask],\n",
        "            cmap='tab20',\n",
        "            alpha=0.6,\n",
        "            s=10\n",
        "        )\n",
        "        plt.colorbar(scatter, label='Cluster')\n",
        "    else:\n",
        "        # S'il n'y a que des points de bruit, tous les afficher\n",
        "        plt.scatter(\n",
        "            historical_umap[:, 0],\n",
        "            historical_umap[:, 1],\n",
        "            c='gray',\n",
        "            alpha=0.3,\n",
        "            s=5\n",
        "        )\n",
        "\n",
        "    plt.title('Clusters des Prompts Historiques (m√©thode am√©lior√©e)')\n",
        "    plt.xlabel('UMAP Dimension 1')\n",
        "    plt.ylabel('UMAP Dimension 2')\n",
        "    plt.savefig('historical_prompt_clusters_improved.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()  # Fermer la figure pour lib√©rer la m√©moire\n",
        "\n",
        "    # Exemples de prompts de chaque cluster\n",
        "    print(\"\\nExemples de prompts par cluster:\")\n",
        "    for cluster_id in sorted(set([label for label in cluster_labels if label != -1])):\n",
        "        # Cr√©er un masque pour ce cluster\n",
        "        cluster_mask = cluster_labels == cluster_id\n",
        "\n",
        "        # Trouver les indices correspondants dans historical_prompts\n",
        "        cluster_indices = np.where(cluster_mask)[0]\n",
        "\n",
        "        # R√©cup√©rer les lignes correspondantes\n",
        "        if len(cluster_indices) > 0:\n",
        "            # √âchantillonner jusqu'√† 5 prompts de ce cluster\n",
        "            sample_indices = np.random.choice(cluster_indices, min(5, len(cluster_indices)), replace=False)\n",
        "\n",
        "            print(f\"\\nCluster {cluster_id} ({len(cluster_indices)} prompts):\")\n",
        "\n",
        "            for idx in sample_indices:\n",
        "                row_idx = historical_prompts.index[idx]\n",
        "                row = historical_prompts.loc[row_idx]\n",
        "                print(f\"  - {row['prompt'][:100]}... (Similarit√©: {row['similarity_score']:.2f}, Concept: {row['most_similar_concept']})\")\n",
        "\n",
        "# Fonction principale pour ex√©cuter l'ensemble du pipeline\n",
        "def run_historical_prompt_analysis(prompts_df, sample_size=1000):\n",
        "    # Identification des prompts historiques avec la m√©thode am√©lior√©e\n",
        "    historical_prompts, prompt_embeddings, is_historical = improved_historical_identification(prompts_df, sample_size)\n",
        "\n",
        "    # Analyse de clusters sur les prompts historiques identifi√©s\n",
        "    historical_prompts_clustered, umap_result, cluster_labels = analyze_historical_clusters(\n",
        "        historical_prompts, prompt_embeddings, is_historical)\n",
        "\n",
        "    return historical_prompts_clustered, umap_result, cluster_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we also export the CSVs\n",
        "\n",
        "def export_clusters_to_csv(historical_prompts, output_dir=\"drive/MyDrive/data/generated/cluster_exports\"):\n",
        "    \"\"\"\n",
        "    Exporte les prompts regroup√©s par cluster dans des fichiers CSV distincts.\n",
        "    Chaque fichier contient les prompts, scores de similarit√© et concepts associ√©s.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    historical_prompts : pandas.DataFrame\n",
        "        DataFrame contenant les prompts historiques avec les colonnes:\n",
        "        - prompt: texte du prompt\n",
        "        - similarity_score: score de similarit√©\n",
        "        - most_similar_concept: concept historique le plus similaire\n",
        "        - cluster: √©tiquette de cluster (-1 pour les points de bruit)\n",
        "        - detection_method: m√©thode ayant d√©tect√© le prompt (embedding ou keyword_only)\n",
        "\n",
        "    output_dir : str\n",
        "        R√©pertoire de sortie pour les fichiers CSV\n",
        "    \"\"\"\n",
        "    # Cr√©er le r√©pertoire de sortie s'il n'existe pas\n",
        "    import os\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        print(f\"R√©pertoire cr√©√©: {output_dir}\")\n",
        "\n",
        "    # Extraire les prompts avec clusters valides (d√©tection par embedding)\n",
        "    clustered_prompts = historical_prompts[historical_prompts['cluster'].notna()].copy()\n",
        "\n",
        "    # Ajouter une version tronqu√©e du prompt pour la pr√©visualisation\n",
        "    clustered_prompts['prompt_preview'] = clustered_prompts['prompt'].apply(\n",
        "        lambda x: x[:100] + '...' if len(x) > 100 else x\n",
        "    )\n",
        "\n",
        "    # Cr√©er un fichier r√©capitulatif pour tous les clusters\n",
        "    summary_file = os.path.join(output_dir, \"all_clusters_summary.csv\")\n",
        "    clusters_summary = clustered_prompts.groupby('cluster').agg(\n",
        "        prompt_count=('prompt', 'count'),\n",
        "        avg_similarity=('similarity_score', 'mean'),\n",
        "        top_concepts=('most_similar_concept', lambda x: x.value_counts().index[0] if len(x) > 0 else 'N/A'),\n",
        "        min_similarity=('similarity_score', 'min'),\n",
        "        max_similarity=('similarity_score', 'max')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Ajouter des exemples de prompts au r√©sum√© (3 exemples par cluster)\n",
        "    def get_sample_prompts(group):\n",
        "        if len(group) <= 3:\n",
        "            return '; '.join(group['prompt_preview'].tolist())\n",
        "        else:\n",
        "            return '; '.join(group.sample(3)['prompt_preview'].tolist())\n",
        "\n",
        "    sample_prompts = clustered_prompts.groupby('cluster').apply(get_sample_prompts).reset_index()\n",
        "    sample_prompts.columns = ['cluster', 'sample_prompts']\n",
        "    clusters_summary = pd.merge(clusters_summary, sample_prompts, on='cluster')\n",
        "\n",
        "    # Enregistrer le r√©sum√©\n",
        "    clusters_summary.to_csv(summary_file, index=False, encoding='utf-8')\n",
        "    print(f\"R√©sum√© des clusters enregistr√© dans {summary_file}\")\n",
        "\n",
        "    # Exporter chaque cluster vers un fichier CSV distinct\n",
        "    unique_clusters = clustered_prompts['cluster'].unique()\n",
        "\n",
        "    for cluster_id in unique_clusters:\n",
        "        # Ignorer les points de bruit pour l'exportation individuelle\n",
        "        if cluster_id == -1:\n",
        "            noise_file = os.path.join(output_dir, \"noise_points.csv\")\n",
        "            noise_prompts = clustered_prompts[clustered_prompts['cluster'] == -1]\n",
        "            if not noise_prompts.empty:\n",
        "                noise_prompts.to_csv(noise_file, index=False, encoding='utf-8')\n",
        "                print(f\"Points de bruit ({len(noise_prompts)}) enregistr√©s dans {noise_file}\")\n",
        "            continue\n",
        "\n",
        "        # Filtrer les prompts de ce cluster\n",
        "        cluster_df = clustered_prompts[clustered_prompts['cluster'] == cluster_id].copy()\n",
        "\n",
        "        # Trier par similarit√© d√©croissante\n",
        "        cluster_df = cluster_df.sort_values('similarity_score', ascending=False)\n",
        "\n",
        "        # Analyser les concepts pr√©sents dans ce cluster\n",
        "        concept_counts = cluster_df['most_similar_concept'].value_counts()\n",
        "        top_concepts = concept_counts.head(3).to_dict()  # Top 3 concepts\n",
        "\n",
        "        # Cr√©er un fichier avec un nom informatif\n",
        "        top_concept = concept_counts.index[0] if len(concept_counts) > 0 else \"inconnu\"\n",
        "        top_concept_safe = ''.join(c if c.isalnum() else '_' for c in top_concept)  # Nom de fichier s√©curis√©\n",
        "\n",
        "        file_name = f\"cluster_{int(cluster_id):02d}_{top_concept_safe}_{len(cluster_df)}_prompts.csv\"\n",
        "        file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        # Enregistrer ce cluster en CSV\n",
        "        cluster_df.to_csv(file_path, index=False, encoding='utf-8')\n",
        "        print(f\"Cluster {int(cluster_id)} ({top_concept}, {len(cluster_df)} prompts) enregistr√© dans {file_name}\")\n",
        "\n",
        "    # Exporter les prompts d√©tect√©s uniquement par mots-cl√©s\n",
        "    keyword_only = historical_prompts[historical_prompts['detection_method'] == 'keyword_only']\n",
        "    if not keyword_only.empty:\n",
        "        keyword_file = os.path.join(output_dir, \"keyword_only_prompts.csv\")\n",
        "        keyword_only.to_csv(keyword_file, index=False, encoding='utf-8')\n",
        "        print(f\"Prompts d√©tect√©s par mots-cl√©s uniquement ({len(keyword_only)}) enregistr√©s dans {keyword_file}\")\n",
        "\n",
        "    # Cr√©er un fichier HTML pour explorer les clusters\n",
        "    create_html_explorer(historical_prompts, os.path.join(output_dir, \"cluster_explorer.html\"))\n",
        "\n",
        "    return clusters_summary\n",
        "\n",
        "def create_html_explorer(historical_prompts, output_file):\n",
        "    \"\"\"\n",
        "    Cr√©e un fichier HTML simple pour explorer les clusters de prompts.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    historical_prompts : pandas.DataFrame\n",
        "        DataFrame contenant les prompts historiques avec clustering\n",
        "    output_file : str\n",
        "        Chemin vers le fichier HTML de sortie\n",
        "    \"\"\"\n",
        "    # Extraire uniquement les prompts avec clusters valides\n",
        "    clustered_prompts = historical_prompts[historical_prompts['cluster'].notna()].copy()\n",
        "\n",
        "    # R√©cup√©rer la liste des clusters uniques (tri√©s)\n",
        "    unique_clusters = sorted(clustered_prompts['cluster'].unique())\n",
        "\n",
        "    # Calculer des statistiques pour chaque cluster\n",
        "    cluster_stats = {}\n",
        "    for cluster_id in unique_clusters:\n",
        "        if cluster_id == -1:  # Traiter les points de bruit s√©par√©ment\n",
        "            continue\n",
        "\n",
        "        cluster_df = clustered_prompts[clustered_prompts['cluster'] == cluster_id]\n",
        "        concept_counts = cluster_df['most_similar_concept'].value_counts().head(3)\n",
        "\n",
        "        cluster_stats[cluster_id] = {\n",
        "            'size': len(cluster_df),\n",
        "            'avg_similarity': cluster_df['similarity_score'].mean(),\n",
        "            'top_concepts': dict(concept_counts),\n",
        "            'samples': cluster_df.sort_values('similarity_score', ascending=False).head(5)['prompt'].tolist()\n",
        "        }\n",
        "\n",
        "    # G√©n√©rer le HTML\n",
        "    html_content = \"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html lang=\"en\">\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "        <title>Explorateur de Clusters de Prompts Historiques</title>\n",
        "        <style>\n",
        "            body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }\n",
        "            h1 { color: #2c3e50; }\n",
        "            h2 { color: #3498db; margin-top: 30px; }\n",
        "            .cluster { border: 1px solid #ddd; padding: 15px; margin: 15px 0; border-radius: 5px; }\n",
        "            .cluster-header { display: flex; justify-content: space-between; }\n",
        "            .concept-tag { display: inline-block; background: #e0f7fa; padding: 3px 8px; margin: 3px; border-radius: 3px; }\n",
        "            .prompt-item { padding: 8px; margin: 5px 0; background: #f9f9f9; border-left: 3px solid #3498db; }\n",
        "            .similarity { font-size: 0.8em; color: #666; }\n",
        "            .stats { color: #7f8c8d; font-size: 0.9em; }\n",
        "            .toggle-button { background: #3498db; color: white; border: none; padding: 5px 10px; cursor: pointer; border-radius: 3px; }\n",
        "            .prompt-list { max-height: 0; overflow: hidden; transition: max-height 0.3s ease-out; }\n",
        "            .expanded { max-height: 2000px; }\n",
        "            .search-container { margin: 20px 0; }\n",
        "            #searchInput { padding: 8px; width: 250px; }\n",
        "            #statsSection { margin-top: 30px; }\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>Explorateur de Clusters de Prompts Historiques</h1>\n",
        "\n",
        "        <div class=\"search-container\">\n",
        "            <input type=\"text\" id=\"searchInput\" placeholder=\"Rechercher des prompts...\">\n",
        "            <button onclick=\"searchPrompts()\">Rechercher</button>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"statsSection\">\n",
        "            <h2>Statistiques g√©n√©rales</h2>\n",
        "            <p>Nombre total de clusters: <strong>\"\"\" + str(len(cluster_stats)) + \"\"\"</strong></p>\n",
        "            <p>Nombre total de prompts clusteris√©s: <strong>\"\"\" + str(len(clustered_prompts)) + \"\"\"</strong></p>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"clustersSection\">\n",
        "    \"\"\"\n",
        "\n",
        "    # Ajouter chaque cluster au HTML\n",
        "    for cluster_id in sorted([c for c in unique_clusters if c != -1]):\n",
        "        stats = cluster_stats[cluster_id]\n",
        "\n",
        "        # Cr√©er les balises de concepts\n",
        "        concept_tags = \"\"\n",
        "        for concept, count in stats['top_concepts'].items():\n",
        "            concept_tags += f'<span class=\"concept-tag\">{concept} ({count})</span>'\n",
        "\n",
        "        # Ajouter les prompts √©chantillons\n",
        "        prompt_items = \"\"\n",
        "        for i, prompt in enumerate(stats['samples']):\n",
        "            # Raccourcir le prompt pour l'affichage\n",
        "            display_prompt = prompt[:200] + \"...\" if len(prompt) > 200 else prompt\n",
        "            prompt_items += f'<div class=\"prompt-item\">{i+1}. {display_prompt}</div>'\n",
        "\n",
        "        # Cr√©er la section de cluster\n",
        "        html_content += f\"\"\"\n",
        "        <div class=\"cluster\" data-cluster-id=\"{int(cluster_id)}\">\n",
        "            <div class=\"cluster-header\">\n",
        "                <h3>Cluster {int(cluster_id)}</h3>\n",
        "                <button class=\"toggle-button\" onclick=\"togglePrompts(this)\">Afficher les prompts</button>\n",
        "            </div>\n",
        "            <div class=\"stats\">\n",
        "                <p><strong>Taille:</strong> {stats['size']} prompts | <strong>Similarit√© moyenne:</strong> {stats['avg_similarity']:.2f}</p>\n",
        "                <p><strong>Concepts principaux:</strong> {concept_tags}</p>\n",
        "            </div>\n",
        "            <div class=\"prompt-list\">\n",
        "                <h4>Exemples de prompts:</h4>\n",
        "                {prompt_items}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Ajouter les points de bruit\n",
        "    noise_df = clustered_prompts[clustered_prompts['cluster'] == -1]\n",
        "    if len(noise_df) > 0:\n",
        "        noise_samples = noise_df.sample(min(5, len(noise_df)))['prompt'].tolist()\n",
        "        noise_items = \"\"\n",
        "        for i, prompt in enumerate(noise_samples):\n",
        "            display_prompt = prompt[:200] + \"...\" if len(prompt) > 200 else prompt\n",
        "            noise_items += f'<div class=\"prompt-item\">{i+1}. {display_prompt}</div>'\n",
        "\n",
        "        html_content += f\"\"\"\n",
        "        <div class=\"cluster\">\n",
        "            <div class=\"cluster-header\">\n",
        "                <h3>Points de bruit</h3>\n",
        "                <button class=\"toggle-button\" onclick=\"togglePrompts(this)\">Afficher les prompts</button>\n",
        "            </div>\n",
        "            <div class=\"stats\">\n",
        "                <p><strong>Taille:</strong> {len(noise_df)} prompts</p>\n",
        "            </div>\n",
        "            <div class=\"prompt-list\">\n",
        "                <h4>Exemples de prompts:</h4>\n",
        "                {noise_items}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Ajouter le JavaScript et fermer les balises HTML\n",
        "    html_content += \"\"\"\n",
        "        </div>\n",
        "\n",
        "        <script>\n",
        "            function togglePrompts(button) {\n",
        "                const list = button.parentNode.nextElementSibling.nextElementSibling;\n",
        "                list.classList.toggle('expanded');\n",
        "                button.textContent = list.classList.contains('expanded') ? 'Masquer les prompts' : 'Afficher les prompts';\n",
        "            }\n",
        "\n",
        "            function searchPrompts() {\n",
        "                const searchTerm = document.getElementById('searchInput').value.toLowerCase();\n",
        "                const clusters = document.querySelectorAll('.cluster');\n",
        "\n",
        "                if (searchTerm === '') {\n",
        "                    // Si la recherche est vide, afficher tous les clusters\n",
        "                    clusters.forEach(cluster => {\n",
        "                        cluster.style.display = 'block';\n",
        "                    });\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                clusters.forEach(cluster => {\n",
        "                    const promptItems = cluster.querySelectorAll('.prompt-item');\n",
        "                    let matchFound = false;\n",
        "\n",
        "                    promptItems.forEach(item => {\n",
        "                        if (item.textContent.toLowerCase().includes(searchTerm)) {\n",
        "                            matchFound = true;\n",
        "                        }\n",
        "                    });\n",
        "\n",
        "                    // Aussi v√©rifier dans les concepts\n",
        "                    const conceptTags = cluster.querySelectorAll('.concept-tag');\n",
        "                    conceptTags.forEach(tag => {\n",
        "                        if (tag.textContent.toLowerCase().includes(searchTerm)) {\n",
        "                            matchFound = true;\n",
        "                        }\n",
        "                    });\n",
        "\n",
        "                    cluster.style.display = matchFound ? 'block' : 'none';\n",
        "                });\n",
        "            }\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    # √âcrire le HTML dans un fichier\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(html_content)\n",
        "\n",
        "    print(f\"Explorateur HTML cr√©√©: {output_file}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSUX_ZVphfsW"
      },
      "source": [
        "### Run the pipline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkAkm77RHuQq",
        "outputId": "e707a90f-2274-4690-ef22-9ab597452695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traitement de tous les 1000 prompts\n",
            "Prompts valides : 987 sur 1000\n",
            "G√©n√©ration des embeddings des prompts...\n",
            "Chargement du mod√®le SentenceTransformer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "G√©n√©ration des embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [06:19<00:00, 12.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G√©n√©ration des embeddings de concepts historiques...\n",
            "Calcul des similarit√©s...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calcul par lots: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:00<00:00, 36.27it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identification de 73 prompts historiques (7.40% de l'√©chantillon)\n",
            "Identification suppl√©mentaire de 163 prompts par mots-cl√©s\n",
            "Total de prompts historiques: 236 (23.91% de l'√©chantillon)\n",
            "Application de la r√©duction dimensionnelle UMAP...\n",
            "Clustering avec DBSCAN...\n",
            "\n",
            "Nombre de prompts par cluster:\n",
            "-1    16\n",
            " 0    13\n",
            " 1     7\n",
            " 2    16\n",
            " 3     6\n",
            " 4     8\n",
            " 5     7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Exemples de prompts par cluster:\n",
            "\n",
            "Cluster 0 (13 prompts):\n",
            "  - a godlike and indomitable helmeted , masked and armored samurai .samurai temple and Rising sun in ba... (Similarit√©: 0.48, Concept: historical costume)\n",
            "  - Slumpunk Cyberpunk City from street view by Dylan Cole , unreal 5, hyperrealistic, realistic, photor... (Similarit√©: 0.53, Concept: dieselpunk)\n",
            "  - king legends knight warrior helmet skyrim mask elder scrolls v nordic armor bethesda adam adamowicz ... (Similarit√©: 0.54, Concept: historical costume)\n",
            "  - Greg Manchess portrait painting of Michelangelo of TMNT as Overwatch character, medium shot, asymmet... (Similarit√©: 0.51, Concept: art deco)\n",
            "  - fully body fashion model beautiful emma watson wearing military armor long dark hair beautiful bone ... (Similarit√©: 0.48, Concept: historical costume)\n",
            "\n",
            "Cluster 1 (7 prompts):\n",
            "  - hyperrealism close - up mythological portrait of a medieval woman's shattered face partially made of... (Similarit√©: 0.48, Concept: historical costume)\n",
            "  - german super soldier, symmetrical portrait scifi, power armor, patriotic american usa storm trooper ... (Similarit√©: 0.49, Concept: historical costume)\n",
            "  - art portrait of an undead ghost in the shell, intricate detailed armour ,8k,by tristan eaton,Stanley... (Similarit√©: 0.46, Concept: historical costume)\n",
            "  - realistic detailed face portrait of a Ghostly Gothic Marie Antoinette by Alphonse Mucha, Ayami Kojim... (Similarit√©: 0.54, Concept: historical costume)\n",
            "  - Portrait of Azula wearing skintight black leather armor, Avatar the Last Airbender, Dungeons and Dra... (Similarit√©: 0.51, Concept: historical costume)\n",
            "\n",
            "Cluster 2 (16 prompts):\n",
            "  - goth woman in a moonlight view, in a forest, a river, tankoban, 4 k, tone mapping, akihiko yoshida, ... (Similarit√©: 0.50, Concept: gothic)\n",
            "  - portraits of art deco skyscrapers taking with a drone, 4k, digital art, photorealism, trending on ar... (Similarit√©: 0.60, Concept: art deco)\n",
            "  - The Great Wall, stars and Paisley-filled skies, art workstations, intricate, highly detailed, digita... (Similarit√©: 0.48, Concept: art deco)\n",
            "  - knight riding a horse by frank frazetta, dynamic pose, chiaroscuro, fantasy, very detailed, dungeons... (Similarit√©: 0.53, Concept: medieval knight)\n",
            "  - playboi carti in steampunk style digital art 4 k the detailed super realistic... (Similarit√©: 0.47, Concept: steampunk)\n",
            "\n",
            "Cluster 3 (6 prompts):\n",
            "  - The British royal family as the Addams family... (Similarit√©: 0.47, Concept: period drama)\n",
            "  - a hyperrealistic painting of a beautiful woman posing with demons by Joe Fenton,... (Similarit√©: 0.51, Concept: art deco)\n",
            "  - digital illustration closeup portrait of cyberpunk samurai in city street at night by makoto shinkai... (Similarit√©: 0.46, Concept: dieselpunk)\n",
            "  - behance winner colorful deco art detailed skeuomorphic very detailed portrait by olbinski airbrush u... (Similarit√©: 0.63, Concept: art deco)\n",
            "  - closeup painting of a very beautiful young mexican cyberpunk woman with a smirk, light blue retro sl... (Similarit√©: 0.47, Concept: steampunk)\n",
            "\n",
            "Cluster 4 (8 prompts):\n",
            "  - 'nature painting of a fractured forest, trending on ArtStation. Extremely detailed and intricate art... (Similarit√©: 0.52, Concept: art deco)\n",
            "  - figurine of luffy wearing an elegant summer blouse, personification, official store photo, commercia... (Similarit√©: 0.47, Concept: historical costume)\n",
            "  - head and shoulders portrait of a armored female paladin portrayed by young carrie fisher, d & d, fan... (Similarit√©: 0.51, Concept: historical costume)\n",
            "  - white turban and shoulder pads with cape wearing john paul ii as piccolo from dragon ball z by claud... (Similarit√©: 0.56, Concept: historical costume)\n",
            "  - Lovecraftian horror, gorgeous, portrait, powerful, intricate, beautiful, masterpiece, elegant, volum... (Similarit√©: 0.48, Concept: art deco)\n",
            "\n",
            "Cluster 5 (7 prompts):\n",
            "  - The most ornate thing possible... (Similarit√©: 0.46, Concept: historical costume)\n",
            "  - portrait ultra dimensional vin diesel entity, accidentally tripping on dmt and acid, psychedelic exp... (Similarit√©: 0.50, Concept: dieselpunk)\n",
            "  - high quality high detail painting by lucian freud and jenny saville, hd, golden eal, turquoise... (Similarit√©: 0.49, Concept: art deco)\n",
            "  - maura allen art... (Similarit√©: 0.50, Concept: art deco)\n",
            "  - hyperrealism oil painting, close-up portrait of medieval euopean fashion model, knight, steel gradie... (Similarit√©: 0.50, Concept: historical costume)\n",
            "Analyse termin√©e avec succ√®s!\n"
          ]
        }
      ],
      "source": [
        "# Ex√©cuter l'analyse et utiliser directement le r√©sultat\n",
        "results, _, _ = run_historical_prompt_analysis(prompts_df)\n",
        "\n",
        "# Exporter avec les r√©sultats\n",
        "summary = export_clusters_to_csv(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2_9wZyIhTMd"
      },
      "source": [
        "## Dataviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpR84gfZzzb4"
      },
      "source": [
        "### 1. Visualisation de la distribution des scores de similarit√©\n",
        "\n",
        "Cette cellule permet de visualiser comment les scores de similarit√© sont distribu√©s et d'√©valuer si le seuil choisi (0.6) est appropri√©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84EXA6Vuzzb5"
      },
      "outputs": [],
      "source": [
        "def visualize_similarity_distribution(similarity_scores, threshold=0.6, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Visualise la distribution des scores de similarit√© et marque le seuil utilis√©.\n",
        "\n",
        "    Args:\n",
        "        similarity_scores: Tableau numpy des scores de similarit√©\n",
        "        threshold: Seuil utilis√© pour filtrer les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Histogramme des scores de similarit√©\n",
        "    plt.hist(similarity_scores, bins=50, alpha=0.7, color='steelblue')\n",
        "\n",
        "    # Ligne verticale pour le seuil\n",
        "    plt.axvline(x=threshold, color='red', linestyle='--',\n",
        "                label=f'Seuil ({threshold})')\n",
        "\n",
        "    # Annotations\n",
        "    plt.title('Distribution des scores de similarit√© avec les concepts historiques',\n",
        "              fontsize=14)\n",
        "    plt.xlabel('Score de similarit√©', fontsize=12)\n",
        "    plt.ylabel('Nombre de prompts', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Annotation des statistiques cl√©s\n",
        "    plt.text(0.02, 0.95,\n",
        "             f\"Total: {len(similarity_scores)}\\nHistoriques: {np.sum(similarity_scores > threshold)} ({np.mean(similarity_scores > threshold):.1%})\",\n",
        "             transform=plt.gca().transAxes,\n",
        "             bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'similarity_distribution.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# D'abord, ex√©cutez le pipeline principal pour g√©n√©rer les donn√©es n√©cessaires si pas d√©j√† fait\n",
        "# historical_prompts, prompt_embeddings, max_similarities = process_prompts_for_historical_content(prompts_df)\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_similarity_distribution(max_similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J781NNphzzb5"
      },
      "source": [
        "### 2. Carte de chaleur des similarit√©s entre concepts historiques\n",
        "\n",
        "Cette cellule permet de visualiser comment les concepts historiques sont reli√©s entre eux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0YCcMfazzb6"
      },
      "outputs": [],
      "source": [
        "def visualize_historical_concepts_similarity(historical_concepts, historical_embeddings, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une carte de chaleur montrant les similarit√©s entre concepts historiques.\n",
        "\n",
        "    Args:\n",
        "        historical_concepts: Liste des concepts historiques\n",
        "        historical_embeddings: Embeddings des concepts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Calculer la matrice de similarit√© entre concepts\n",
        "    concept_similarity = cosine_similarity(historical_embeddings)\n",
        "\n",
        "    # Cr√©er une figure de taille appropri√©e\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Cr√©er la heatmap avec seaborn\n",
        "    sns.heatmap(concept_similarity, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",\n",
        "                xticklabels=historical_concepts, yticklabels=historical_concepts)\n",
        "\n",
        "    plt.title(\"Similarit√© entre les concepts historiques\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'historical_concepts_similarity.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_historical_concepts_similarity(historical_concepts, historical_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHMtSy0yzzb6"
      },
      "source": [
        "### 3. Projection UMAP des prompts avec coloration par concept le plus similaire\n",
        "Cette visualisation permet de voir comment les prompts se regroupent naturellement et si les concepts les plus similaires forment des clusters coh√©rents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlMNhI9Nzzb6"
      },
      "outputs": [],
      "source": [
        "def visualize_umap_by_concept(historical_prompts, historical_umap, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Visualise la projection UMAP des prompts, color√©s par concept historique le plus similaire.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques avec leur concept le plus similaire\n",
        "        historical_umap: Coordonn√©es UMAP des prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import os\n",
        "    from matplotlib.colors import ListedColormap\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Obtenir les concepts uniques\n",
        "    unique_concepts = historical_prompts['most_similar_concept'].unique()\n",
        "    n_concepts = len(unique_concepts)\n",
        "\n",
        "    # Cr√©er un mapping des concepts aux indices\n",
        "    concept_to_idx = {concept: i for i, concept in enumerate(unique_concepts)}\n",
        "\n",
        "    # Obtenir un tableau numpy des indices de concepts\n",
        "    concept_indices = np.array([concept_to_idx[concept] for concept in historical_prompts['most_similar_concept']])\n",
        "\n",
        "    # Cr√©er une colormap avec suffisamment de couleurs distinctes\n",
        "    import matplotlib.cm as cm\n",
        "    if n_concepts <= 10:\n",
        "        cmap = ListedColormap(plt.cm.tab10.colors[:n_concepts])\n",
        "    elif n_concepts <= 20:\n",
        "        cmap = ListedColormap(plt.cm.tab20.colors[:n_concepts])\n",
        "    else:\n",
        "        cmap = plt.cm.nipy_spectral\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Scatter plot avec coloration par concept\n",
        "    scatter = plt.scatter(historical_umap[:, 0], historical_umap[:, 1],\n",
        "                         c=concept_indices, cmap=cmap,\n",
        "                         alpha=0.7, s=10)\n",
        "\n",
        "    # Cr√©er une l√©gende explicite\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
        "                              markerfacecolor=cmap(concept_to_idx[concept]),\n",
        "                              markersize=8, label=concept)\n",
        "                       for concept in unique_concepts]\n",
        "\n",
        "    plt.legend(handles=legend_elements, loc='upper right',\n",
        "               bbox_to_anchor=(1.1, 1), ncol=1)\n",
        "\n",
        "    plt.title('Projection UMAP des prompts historiques par concept', fontsize=14)\n",
        "    plt.xlabel('UMAP Dimension 1', fontsize=12)\n",
        "    plt.ylabel('UMAP Dimension 2', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'umap_by_concept.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_umap_by_concept(historical_prompts, historical_umap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpCXtfFezzb6"
      },
      "source": [
        "### 4. Nuage de mots pour chaque cluster\n",
        "\n",
        "Cette visualisation permet d'explorer les termes les plus fr√©quents dans chaque cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HKCYht_zzb7"
      },
      "outputs": [],
      "source": [
        "def generate_cluster_wordclouds(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    G√©n√®re un nuage de mots pour chaque cluster identifi√©.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques avec leurs clusters\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    from wordcloud import WordCloud\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "    # T√©l√©charger les stopwords si n√©cessaire\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Pour chaque cluster\n",
        "    for cluster_id in sorted(historical_prompts['cluster'].unique()):\n",
        "        if cluster_id == -1:  # Ignorer les points de bruit\n",
        "            continue\n",
        "\n",
        "        # Filtrer les prompts de ce cluster\n",
        "        cluster_prompts = historical_prompts[historical_prompts['cluster'] == cluster_id]['prompt']\n",
        "\n",
        "        if len(cluster_prompts) == 0:\n",
        "            continue\n",
        "\n",
        "        # Combiner tous les textes\n",
        "        text = ' '.join(cluster_prompts)\n",
        "\n",
        "        # Cr√©er le nuage de mots\n",
        "        wordcloud = WordCloud(\n",
        "            width=800,\n",
        "            height=400,\n",
        "            background_color='white',\n",
        "            stopwords=stop_words,\n",
        "            max_words=100,\n",
        "            contour_width=3\n",
        "        ).generate(text)\n",
        "\n",
        "        # Afficher et sauvegarder\n",
        "        plt.figure(figsize=(16, 8))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Nuage de mots pour le Cluster {cluster_id} ({len(cluster_prompts)} prompts)',\n",
        "                 fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, f'wordcloud_cluster_{cluster_id}.png'), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"Nuages de mots g√©n√©r√©s pour {len(historical_prompts['cluster'].unique()) - 1} clusters\")\n",
        "\n",
        "# Exemple d'utilisation\n",
        "generate_cluster_wordclouds(historical_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caLeAOPFzzb7"
      },
      "source": [
        "### 5. Distribution des concepts historiques par cluster\n",
        "Cette visualisation montre comment les diff√©rents concepts historiques sont distribu√©s dans les clusters identifi√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW_xK_49zzb8"
      },
      "outputs": [],
      "source": [
        "def visualize_concepts_by_cluster(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une heatmap montrant la distribution des concepts historiques par cluster.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Ignorer les points de bruit (cluster -1) si pr√©sents\n",
        "    if -1 in historical_prompts['cluster'].unique():\n",
        "        df_filtered = historical_prompts[historical_prompts['cluster'] != -1].copy()\n",
        "    else:\n",
        "        df_filtered = historical_prompts.copy()\n",
        "\n",
        "    # Cr√©er une table de contingence\n",
        "    cross_tab = pd.crosstab(\n",
        "        df_filtered['most_similar_concept'],\n",
        "        df_filtered['cluster'],\n",
        "        normalize='index'\n",
        "    )\n",
        "\n",
        "    # Tri pour une meilleure visualisation\n",
        "    # On trie les concepts par cluster dominant\n",
        "    dominant_clusters = cross_tab.idxmax(axis=1)\n",
        "    sorted_concepts = dominant_clusters.sort_values().index\n",
        "    cross_tab = cross_tab.loc[sorted_concepts]\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    sns.heatmap(cross_tab, annot=True, cmap=\"YlGnBu\", fmt='.0%')\n",
        "    plt.title('Distribution des concepts historiques par cluster', fontsize=16)\n",
        "    plt.ylabel('Concept historique', fontsize=14)\n",
        "    plt.xlabel('Cluster', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'concept_cluster_distribution.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_concepts_by_cluster(historical_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nj9wR-fzzb8"
      },
      "source": [
        "### 6. Analyse des termes les plus communs par concept historique\n",
        "\n",
        "Cette visualisation aide √† comprendre quels termes sont les plus associ√©s √† chaque concept historique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGSJ72tAzzb8"
      },
      "outputs": [],
      "source": [
        "def analyze_terms_by_concept(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Analyse et visualise les termes les plus fr√©quents pour chaque concept historique.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    import nltk\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    from collections import Counter\n",
        "\n",
        "    # T√©l√©charger les ressources NLTK n√©cessaires\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Pour chaque concept historique\n",
        "    for concept in historical_prompts['most_similar_concept'].unique():\n",
        "        # Filtrer les prompts de ce concept\n",
        "        concept_prompts = historical_prompts[historical_prompts['most_similar_concept'] == concept]['prompt']\n",
        "\n",
        "        # Combiner tous les prompts\n",
        "        text = ' '.join(concept_prompts)\n",
        "\n",
        "        # Tokenizer\n",
        "        tokens = word_tokenize(text.lower())\n",
        "\n",
        "        # Filtrer les stopwords et les tokens courts\n",
        "        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words and len(word) > 2]\n",
        "\n",
        "        # Compter les occurrences\n",
        "        word_counts = Counter(filtered_tokens)\n",
        "\n",
        "        # Prendre les N mots les plus fr√©quents\n",
        "        top_n = 20\n",
        "        top_words = word_counts.most_common(top_n)\n",
        "\n",
        "        # Pr√©parer les donn√©es pour le graphique\n",
        "        words = [word for word, count in top_words]\n",
        "        counts = [count for word, count in top_words]\n",
        "\n",
        "        # Cr√©er le graphique\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.barh(words[::-1], counts[::-1], color='steelblue')\n",
        "        plt.xlabel('Fr√©quence')\n",
        "        plt.title(f'Termes les plus fr√©quents pour \"{concept}\" ({len(concept_prompts)} prompts)',\n",
        "                 fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, f'terms_{concept.replace(\" \", \"_\")}.png'), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"Analyse des termes g√©n√©r√©e pour {len(historical_prompts['most_similar_concept'].unique())} concepts\")\n",
        "\n",
        "# Exemple d'utilisation\n",
        "analyze_terms_by_concept(historical_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kRRe0dgzzb9"
      },
      "source": [
        "### 7. Visualisation interactive avec Plotly\n",
        "\n",
        "Cette cellule cr√©e une visualisation interactive de la projection UMAP qui permet d'explorer les prompts historiques de mani√®re plus interactive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27WS7FxPzzb9"
      },
      "outputs": [],
      "source": [
        "def create_interactive_visualization(historical_prompts, historical_umap, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une visualisation interactive des prompts historiques avec Plotly.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        historical_umap: Coordonn√©es UMAP des prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import plotly.express as px\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Cr√©er un DataFrame pour Plotly\n",
        "    viz_df = pd.DataFrame({\n",
        "        'UMAP1': historical_umap[:, 0],\n",
        "        'UMAP2': historical_umap[:, 1],\n",
        "        'Cluster': historical_prompts['cluster'],\n",
        "        'Concept': historical_prompts['most_similar_concept'],\n",
        "        'Score': historical_prompts['similarity_score'],\n",
        "        'Prompt': historical_prompts['prompt']\n",
        "    })\n",
        "\n",
        "    # Cr√©er la visualisation interactive\n",
        "    fig = px.scatter(\n",
        "        viz_df,\n",
        "        x='UMAP1',\n",
        "        y='UMAP2',\n",
        "        color='Concept',\n",
        "        hover_data=['Prompt', 'Score', 'Cluster'],\n",
        "        opacity=0.7,\n",
        "        title='Exploration interactive des prompts historiques',\n",
        "        template='plotly_white',\n",
        "        color_discrete_sequence=px.colors.qualitative.Bold\n",
        "    )\n",
        "\n",
        "    # Am√©liorer la mise en page\n",
        "    fig.update_layout(\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=-0.2,\n",
        "            xanchor=\"center\",\n",
        "            x=0.5\n",
        "        ),\n",
        "        width=1200,\n",
        "        height=800\n",
        "    )\n",
        "\n",
        "    # Enregistrer en tant que fichier HTML autonome\n",
        "    fig.write_html(os.path.join(output_path, 'interactive_visualization.html'))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Exemple d'utilisation\n",
        "fig = create_interactive_visualization(historical_prompts, historical_umap)\n",
        "fig.show()  # Afficher dans le notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3hWpg1zzb-"
      },
      "source": [
        "### 8. R√©seau de co-occurrence de concepts dans les clusters\n",
        "Cette visualisation montre comment les concepts historiques sont li√©s entre eux √† travers leur pr√©sence dans les m√™mes clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwOIg5Qozzb_"
      },
      "outputs": [],
      "source": [
        "def visualize_concept_network(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une visualisation en r√©seau des relations entre concepts historiques\n",
        "    bas√©e sur leur co-occurrence dans les clusters.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Filtrer pour exclure les points de bruit\n",
        "    if -1 in historical_prompts['cluster'].unique():\n",
        "        df_filtered = historical_prompts[historical_prompts['cluster'] != -1].copy()\n",
        "    else:\n",
        "        df_filtered = historical_prompts.copy()\n",
        "\n",
        "    # Cr√©er un graphe\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Ajouter des n≈ìuds pour chaque concept\n",
        "    concepts = df_filtered['most_similar_concept'].unique()\n",
        "    for concept in concepts:\n",
        "        count = df_filtered[df_filtered['most_similar_concept'] == concept].shape[0]\n",
        "        G.add_node(concept, size=count, count=count)\n",
        "\n",
        "    # Pour chaque cluster, cr√©er des liens entre concepts pr√©sents\n",
        "    for cluster in df_filtered['cluster'].unique():\n",
        "        # Obtenir les concepts dans ce cluster\n",
        "        cluster_concepts = df_filtered[df_filtered['cluster'] == cluster]['most_similar_concept'].unique()\n",
        "\n",
        "        # Cr√©er des liens pour chaque paire de concepts\n",
        "        for i, concept1 in enumerate(cluster_concepts):\n",
        "            for concept2 in cluster_concepts[i+1:]:\n",
        "                # Si le lien existe d√©j√†, augmenter son poids\n",
        "                if G.has_edge(concept1, concept2):\n",
        "                    G[concept1][concept2]['weight'] += 1\n",
        "                else:\n",
        "                    G.add_edge(concept1, concept2, weight=1)\n",
        "\n",
        "    # Taille des n≈ìuds bas√©e sur la fr√©quence\n",
        "    node_sizes = [G.nodes[node]['size'] * 20 for node in G.nodes]\n",
        "\n",
        "    # √âpaisseur des liens bas√©e sur les poids\n",
        "    edge_weights = [G[u][v]['weight'] * 0.5 for u, v in G.edges]\n",
        "\n",
        "    # Positionner les n≈ìuds\n",
        "    pos = nx.spring_layout(G, seed=42, k=0.3)\n",
        "\n",
        "    plt.figure(figsize=(14, 12))\n",
        "\n",
        "    # Dessiner les n≈ìuds\n",
        "    nx.draw_networkx_nodes(G, pos,\n",
        "                          node_size=node_sizes,\n",
        "                          node_color='skyblue',\n",
        "                          alpha=0.8)\n",
        "\n",
        "    # Dessiner les liens\n",
        "    nx.draw_networkx_edges(G, pos,\n",
        "                          width=edge_weights,\n",
        "                          alpha=0.5,\n",
        "                          edge_color='gray')\n",
        "\n",
        "    # Ajouter les √©tiquettes\n",
        "    nx.draw_networkx_labels(G, pos, font_size=10, font_family='sans-serif')\n",
        "\n",
        "    plt.title('R√©seau de co-occurrence des concepts historiques', fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'concept_network.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return G\n",
        "\n",
        "# Exemple d'utilisation\n",
        "concept_network = visualize_concept_network(historical_prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byOi5gGezzb_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "citation-manager": {
      "items": {}
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "negotiating_past",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
