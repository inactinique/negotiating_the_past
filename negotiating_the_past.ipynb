{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncks0uTDzzbr"
      },
      "source": [
        "# negotiating the past"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAMm3ta9zzbt"
      },
      "source": [
        "To install the environment, please read README.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9P3w6zjzzbu"
      },
      "source": [
        "## Project Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOnXyO8-zzbv"
      },
      "source": [
        "This presentation explores the intersection of historical imagination, artificial intelligence, and collective memory. We'll examine how users \"negotiate\" with AI systems to express their conceptions of the past, and how these interactions can reveal tensions between user expectations and AI-embedded historical patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3hVHSpLzzbv"
      },
      "source": [
        "## Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gYah1yFzzbw"
      },
      "source": [
        "1. **Theoretical Framework**: How LLMs encode historical perspectives\n",
        "2. **Methodological Approach**: Analyzing historical references in prompts\n",
        "3. **Results Analysis**: What prompt analysis reveals about historical imagination\n",
        "4. **Conclusion**: New spaces for historical negotiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u9weciKzzbw"
      },
      "source": [
        "# Part I: Theoretical Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyk3aN1Wzzbx"
      },
      "source": [
        "## LLMs and Embedded Historical Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzyS9Vqzzbx"
      },
      "source": [
        "- LLMs as Statistical Pattern Recognizers\n",
        "- Training Data as Historical Record\n",
        "- Historical Biases in Language Models\n",
        "- \"Stochastic Parrots\" and Historical Truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InBd6u7Vzzbz"
      },
      "source": [
        "## Technical Foundation of LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OpZ0_Mtzzbz"
      },
      "source": [
        "LLMs rely on transformer architectures that predict tokens based on previous context. Their \"knowledge\" of history comes from statistical patterns in training data, not genuine understanding. This creates an interesting dynamic when users prompt these systems about historical topics - the system's responses reveal embedded historical narratives from their training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2oCbKbtzzbz"
      },
      "source": [
        "## Historical Knowledge in Vector Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPItExUhzzb0"
      },
      "source": [
        "- Word embeddings capture semantic relationships\n",
        "- Historical concepts represented as vectors\n",
        "- Temporal relationships encoded in semantic proximity\n",
        "- Cultural associations embedded in language patterns\n",
        "\n",
        "Within the vector space of LLMs, historical concepts are encoded as points in multidimensional space. The relationships between historical events, figures, and concepts are captured in the distances and directions between these vectors. These semantic relationships reflect collective memory patterns from the training corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90GoVLlIzzb0"
      },
      "source": [
        "## Collective Memory and LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77zYNsdbzzb0"
      },
      "source": [
        "- LLMs as repositories of digitized collective memory\n",
        "- Training data selection as memory politics\n",
        "- The \"averaged\" nature of AI-generated historical narratives\n",
        "- Absence of contested memory in statistical consensus\n",
        "\n",
        "From a memory studies perspective, LLMs function as repositories of digitized collective memory. The selection of training data constitutes a form of memory politics, determining which historical perspectives are included or excluded. The statistical nature of these models produces \"averaged\" historical narratives that often elide contestation and complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDuaGCSnzzb0"
      },
      "source": [
        "# Part II: Methodological Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmRnFRyxzzb1"
      },
      "source": [
        "## The Challenge of Historical Prompt Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgpMAiaYzzb1"
      },
      "source": [
        "- Beyond simple keyword approaches\n",
        "- Historical references: explicit vs. implicit\n",
        "- Temporality in language\n",
        "- Building a robust identification strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHjGRP_Xzzb1"
      },
      "source": [
        "Identifying prompts that reference history requires more sophisticated approaches than simple keyword matching. Historical references can be explicit (\"Napoleon Bonaparte\") or implicit (\"the Emperor's exile\"), and may involve complex temporal markers. Our methodology must capture this complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PrCaiB6xzzb1",
        "outputId": "81c8529a-2890-478a-ae36-59eccdb24032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22->umap-learn) (3.6.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#We load the necessary libraries. If using colab, you might want to restart your kernel afterwards\n",
        "\n",
        "!python --version\n",
        "!pip install umap-learn\n",
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we mount google drive. Skip if you're not using google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vtFna26EPTe",
        "outputId": "9b08e5fd-a9d1-49ea-a03f-b3da657d79f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaKgggqHzzb2"
      },
      "source": [
        "## Creating a Historical Prompt Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dX5tD0evzzb3",
        "outputId": "903365c3-e2f8-45ab-9a6e-7c37c860d645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Loading the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import ssl\n",
        "\n",
        "# Make sure you have the necessary NLTK resources\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Read the CSV file -- we load only 10 000 rows and the first column for this dataset of prompts.\n",
        "prompts_df = pd.read_csv(\"drive/MyDrive/data/prompts.csv\", on_bad_lines='skip', nrows=10000, usecols=[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWV0Mqlazzb3"
      },
      "source": [
        "## Historical Reference Detection Approach With DistilBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up the pipeline"
      ],
      "metadata": {
        "id": "BWAtuQpchZ_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i7kCiBnizzb3",
        "outputId": "709917ae-75ec-4879-a6d6-5a8592110adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DistilBERT model...\n",
            "Model loaded on CPU\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from umap import UMAP\n",
        "from sklearn.cluster import DBSCAN\n",
        "from tqdm import tqdm  # For progress bars\n",
        "import gc  # Garbage collection\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "import os\n",
        "\n",
        "# Set the number of CPU cores to use\n",
        "num_cpu_cores = 8\n",
        "torch.set_num_threads(num_cpu_cores)  # Set PyTorch to use your 8 cores\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(num_cpu_cores)  # OpenMP threads\n",
        "os.environ[\"MKL_NUM_THREADS\"] = str(num_cpu_cores)  # MKL threads\n",
        "\n",
        "# Load DistilBERT model and tokenizer\n",
        "print(\"Loading DistilBERT model...\")\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Switch to CPU mode explicitly\n",
        "model = model.to(\"cpu\")\n",
        "print(\"Model loaded on CPU\")\n",
        "\n",
        "# Function to get DistilBERT embeddings for a batch of texts\n",
        "def process_batch(batch_texts, tokenizer, model):\n",
        "    # Filter out None values and empty strings\n",
        "    batch_texts = [text for text in batch_texts if isinstance(text, str) and text.strip()]\n",
        "\n",
        "    if not batch_texts:\n",
        "        return np.array([])\n",
        "\n",
        "    # Tokenize the texts\n",
        "    encoded_input = tokenizer(batch_texts, padding=True, truncation=True,\n",
        "                             max_length=256, return_tensors='pt')\n",
        "\n",
        "    # Compute token embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_input)\n",
        "\n",
        "    # Use the [CLS] token embedding as the sentence embedding\n",
        "    sentence_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Clear CUDA cache if using GPU\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return sentence_embeddings\n",
        "\n",
        "# Function to split a list into chunks\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "# Function to get embeddings with multiprocessing\n",
        "def get_distilbert_embeddings_parallel(texts, tokenizer, model, batch_size=32, n_processes=8):\n",
        "    # Split texts into batches\n",
        "    batches = list(chunks(texts, batch_size))\n",
        "\n",
        "    # Process batches in parallel\n",
        "    with multiprocessing.Pool(processes=n_processes) as pool:\n",
        "        process_func = partial(process_batch, tokenizer=tokenizer, model=model)\n",
        "        results = list(tqdm(pool.imap(process_func, batches), total=len(batches), desc=\"Generating embeddings\"))\n",
        "\n",
        "    # Filter out empty results and concatenate\n",
        "    results = [r for r in results if r.size > 0]\n",
        "    if not results:\n",
        "        return np.array([])\n",
        "\n",
        "    return np.concatenate(results, axis=0)\n",
        "\n",
        "# Memory-efficient function to calculate cosine similarities in chunks\n",
        "def calculate_similarities_in_chunks(embeddings_a, embeddings_b, chunk_size=1000):\n",
        "    n_samples = embeddings_a.shape[0]\n",
        "    n_features = embeddings_b.shape[0]\n",
        "    similarities = np.zeros((n_samples, n_features))\n",
        "\n",
        "    for i in tqdm(range(0, n_samples, chunk_size), desc=\"Calculating similarities\"):\n",
        "        end_idx = min(i + chunk_size, n_samples)\n",
        "        chunk_similarities = cosine_similarity(\n",
        "            embeddings_a[i:end_idx],\n",
        "            embeddings_b\n",
        "        )\n",
        "        similarities[i:end_idx] = chunk_similarities\n",
        "\n",
        "    return similarities\n",
        "\n",
        "# Main processing pipeline\n",
        "def process_prompts_for_historical_content(prompts_df, sample_size=100000):\n",
        "    # Sample if dataset is large\n",
        "    if len(prompts_df) > sample_size:\n",
        "        sample_df = prompts_df.sample(sample_size, random_state=42)\n",
        "        print(f\"Sampled {sample_size} prompts from {len(prompts_df)} total\")\n",
        "    else:\n",
        "        sample_df = prompts_df.copy()\n",
        "        print(f\"Processing all {len(sample_df)} prompts\")\n",
        "\n",
        "    # Clean memory\n",
        "    gc.collect()\n",
        "\n",
        "    # Get list of prompts\n",
        "    prompts_list = sample_df['prompt'].fillna('').tolist()\n",
        "\n",
        "    # Create a mask for valid texts before generating embeddings\n",
        "    valid_text_mask = [isinstance(text, str) and bool(text.strip()) for text in prompts_list]\n",
        "    valid_prompts = [text for i, text in enumerate(prompts_list) if valid_text_mask[i]]\n",
        "\n",
        "    print(f\"Valid prompts: {len(valid_prompts)} out of {len(prompts_list)}\")\n",
        "\n",
        "    # Generate embeddings only for valid texts\n",
        "    print(\"Generating prompt embeddings...\")\n",
        "    prompt_embeddings = get_distilbert_embeddings_parallel(\n",
        "        valid_prompts,\n",
        "        tokenizer,\n",
        "        model,\n",
        "        batch_size=32,  # Smaller batches for memory efficiency\n",
        "        n_processes=num_cpu_cores\n",
        "    )\n",
        "\n",
        "    # Filter sample_df to include only rows with valid text\n",
        "    sample_df = sample_df[valid_text_mask].reset_index(drop=True)\n",
        "\n",
        "    # Now the length of sample_df and prompt_embeddings should match\n",
        "    assert len(sample_df) == prompt_embeddings.shape[0], \"Length mismatch between DataFrame and embeddings\"\n",
        "\n",
        "    # Define historical concepts\n",
        "    historical_concepts = [\n",
        "        \"ancient history\", \"medieval times\", \"renaissance period\",\n",
        "        \"world war\", \"cold war\", \"industrial revolution\",\n",
        "        \"historic events\", \"historical figures\", \"archaeological findings\",\n",
        "        \"prehistoric era\", \"colonial period\", \"civil rights movement\",\n",
        "        \"past civilizations\", \"historical artifacts\", \"ancient empires\",\n",
        "        \"historical battles\", \"kings and queens\", \"historical architecture\"\n",
        "    ]\n",
        "\n",
        "    # Generate embeddings for historical concepts\n",
        "    print(\"Generating historical concept embeddings...\")\n",
        "    historical_embeddings = get_distilbert_embeddings_parallel(\n",
        "        historical_concepts,\n",
        "        tokenizer,\n",
        "        model,\n",
        "        batch_size=len(historical_concepts),  # Process all concepts in one batch\n",
        "        n_processes=1  # No need for parallelism with small number of concepts\n",
        "    )\n",
        "\n",
        "    # Clean memory\n",
        "    gc.collect()\n",
        "\n",
        "    # Calculate similarities in memory-efficient chunks\n",
        "    print(\"Calculating similarities...\")\n",
        "    similarity_matrix = calculate_similarities_in_chunks(\n",
        "        prompt_embeddings,\n",
        "        historical_embeddings,\n",
        "        chunk_size=1000\n",
        "    )\n",
        "\n",
        "    # For each prompt, get the maximum similarity to any historical concept\n",
        "    max_similarities = np.max(similarity_matrix, axis=1)\n",
        "\n",
        "    # Find the index of the most similar historical concept for each prompt\n",
        "    most_similar_concept_idx = np.argmax(similarity_matrix, axis=1)\n",
        "    sample_df['most_similar_concept'] = [historical_concepts[idx] for idx in most_similar_concept_idx]\n",
        "    sample_df['similarity_score'] = max_similarities\n",
        "\n",
        "    # Filter prompts with similarity scores above a threshold\n",
        "    threshold = 0.6  # Adjust based on your needs\n",
        "    historical_prompts = sample_df[max_similarities > threshold].copy()\n",
        "\n",
        "    print(f\"Identified {len(historical_prompts)} historical prompts ({len(historical_prompts)/len(sample_df):.2%} of sample)\")\n",
        "\n",
        "    # Clean memory before UMAP/clustering\n",
        "    del similarity_matrix\n",
        "    gc.collect()\n",
        "\n",
        "    return historical_prompts, prompt_embeddings, max_similarities\n",
        "\n",
        "# Assuming prompts_df is already loaded\n",
        "# historical_prompts, prompt_embeddings, max_similarities = process_prompts_for_historical_content(prompts_df)\n",
        "\n",
        "# The rest of the code (UMAP and clustering) can remain largely the same as before\n",
        "def analyze_historical_clusters(historical_prompts, prompt_embeddings, max_similarities, threshold=0.6):\n",
        "    if len(historical_prompts) > 10:  # Need at least a few samples for clustering\n",
        "        # Get embeddings for the filtered historical prompts\n",
        "        historical_embeddings = prompt_embeddings[max_similarities > threshold]\n",
        "\n",
        "        print(\"Applying UMAP dimensionality reduction...\")\n",
        "        # Apply UMAP with CPU optimization\n",
        "        umap_model = UMAP(n_neighbors=15, min_dist=0.1, random_state=42,\n",
        "                          n_jobs=num_cpu_cores)  # Use all cores\n",
        "        historical_umap = umap_model.fit_transform(historical_embeddings)\n",
        "\n",
        "        print(\"Clustering with DBSCAN...\")\n",
        "        # Apply DBSCAN\n",
        "        dbscan = DBSCAN(eps=0.5, min_samples=5, n_jobs=num_cpu_cores)  # Use all cores\n",
        "        cluster_labels = dbscan.fit_predict(historical_umap)\n",
        "\n",
        "        # Add cluster labels to the dataframe\n",
        "        historical_prompts['cluster'] = cluster_labels\n",
        "\n",
        "        # Generate visualizations and report\n",
        "        generate_cluster_report(historical_prompts, historical_umap, cluster_labels)\n",
        "\n",
        "        return historical_prompts, historical_umap, cluster_labels\n",
        "    else:\n",
        "        print(\"Not enough historical prompts for clustering\")\n",
        "        return historical_prompts, None, None\n",
        "\n",
        "def generate_cluster_report(historical_prompts, historical_umap, cluster_labels):\n",
        "    # Count number of prompts per cluster\n",
        "    cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
        "    print(\"\\nNumber of prompts per cluster:\")\n",
        "    print(cluster_counts)\n",
        "\n",
        "    # Visualize the clusters\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    # Exclude noise points (cluster -1) for better visualization\n",
        "    non_noise_mask = cluster_labels != -1\n",
        "\n",
        "    scatter = plt.scatter(\n",
        "        historical_umap[non_noise_mask, 0],\n",
        "        historical_umap[non_noise_mask, 1],\n",
        "        c=cluster_labels[non_noise_mask],\n",
        "        cmap='tab20',\n",
        "        alpha=0.6,\n",
        "        s=10\n",
        "    )\n",
        "    plt.colorbar(scatter, label='Cluster')\n",
        "    plt.title('Clusters of Historical Prompts (DistilBERT method)')\n",
        "    plt.xlabel('UMAP Dimension 1')\n",
        "    plt.ylabel('UMAP Dimension 2')\n",
        "    plt.savefig('historical_prompt_clusters_distilbert.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()  # Close the figure to free memory\n",
        "\n",
        "    # Sample prompts from each cluster\n",
        "    print(\"\\nSample prompts from each cluster:\")\n",
        "    for cluster_id in sorted(historical_prompts['cluster'].unique()):\n",
        "        if cluster_id == -1:\n",
        "            continue  # Skip noise points\n",
        "\n",
        "        cluster_prompts = historical_prompts[historical_prompts['cluster'] == cluster_id]\n",
        "        print(f\"\\nCluster {cluster_id} ({len(cluster_prompts)} prompts):\")\n",
        "\n",
        "        # Sample up to 5 prompts from this cluster\n",
        "        samples = cluster_prompts.sample(min(5, len(cluster_prompts)))\n",
        "        for _, row in samples.iterrows():\n",
        "            print(f\"  - {row['prompt'][:100]}... (Similarity: {row['similarity_score']:.2f}, Concept: {row['most_similar_concept']})\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the pipline"
      ],
      "metadata": {
        "id": "dSUX_ZVphfsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your data\n",
        "    # prompts_df = pd.read_csv(\"prompts.csv\")\n",
        "\n",
        "    # Run the complete pipeline\n",
        "    historical_prompts, prompt_embeddings, max_similarities = process_prompts_for_historical_content(prompts_df)\n",
        "    historical_prompts, umap_result, cluster_labels = analyze_historical_clusters(\n",
        "        historical_prompts, prompt_embeddings, max_similarities)\n",
        "\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "YkAkm77RHuQq",
        "outputId": "abecf6b5-d5f3-4065-d758-ea3e2a5f6511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing all 10000 prompts\n",
            "Valid prompts: 9904 out of 10000\n",
            "Generating prompt embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 310/310 [31:19<00:00,  6.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating historical concept embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating similarities...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating similarities: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 25.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified 9904 historical prompts (100.00% of sample)\n",
            "Applying UMAP dimensionality reduction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustering with DBSCAN...\n",
            "\n",
            "Number of prompts per cluster:\n",
            "0    9814\n",
            "1      16\n",
            "2      16\n",
            "3      11\n",
            "4      17\n",
            "5       9\n",
            "6      21\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample prompts from each cluster:\n",
            "\n",
            "Cluster 0 (9814 prompts):\n",
            "  - an orange tabby cat driving a car, his paws are on the steering wheel... (Similarity: 0.86, Concept: kings and queens)\n",
            "  - highly detailed portrait of clairelynnd, photographic realistic background, ringlet hair by atey gha... (Similarity: 0.88, Concept: prehistoric era)\n",
            "  - captain sicko from star trek : deep space nine. realistic concept art painting,... (Similarity: 0.91, Concept: prehistoric era)\n",
            "  - Caleb McLaughlin as miles morales spiderman, 8k, super realistic, cinematic cinematography, marvel m... (Similarity: 0.83, Concept: prehistoric era)\n",
            "  - astronaut holding a lightsaber, digital art, artstation... (Similarity: 0.87, Concept: prehistoric era)\n",
            "\n",
            "Cluster 1 (16 prompts):\n",
            "  - face icon stylized minimalist ben hur, loftis, cory behance hd by jesper ejsing, by rhads, makoto sh... (Similarity: 0.85, Concept: renaissance period)\n",
            "  - face icon stylized minimalist street sharks, loftis, cory behance hd by jesper ejsing, by rhads, mak... (Similarity: 0.85, Concept: renaissance period)\n",
            "  - face icon stylized minimalist cowboy bebop, loftis, cory behance hd by jesper ejsing, by rhads, mako... (Similarity: 0.85, Concept: renaissance period)\n",
            "  - face icon stylized minimalist superman, loftis, cory behance hd by jesper ejsing, by rhads, makoto s... (Similarity: 0.85, Concept: prehistoric era)\n",
            "  - full body shot of Megan fox by wlop, rossdraws, mingchen shen, bangkuart, sakimichan, yan gisuka, je... (Similarity: 0.82, Concept: prehistoric era)\n",
            "\n",
            "Cluster 2 (16 prompts):\n",
            "  - high quality pastel coloured film close up wide angle photograph of a model wearing clothing swimmin... (Similarity: 0.82, Concept: prehistoric era)\n",
            "  - Tracer from Overwatch, posing for a Portrait. Clean Backdrop. Dramatic Lighting. Stylistic Colors. M... (Similarity: 0.83, Concept: prehistoric era)\n",
            "  - un ultra high definition studio quality photographic art portrait of a young man standing on the roo... (Similarity: 0.82, Concept: prehistoric era)\n",
            "  - A hyper realistic and detailed head portrait photography of a Rachael of Blade Runner on a futuristi... (Similarity: 0.82, Concept: prehistoric era)\n",
            "  - high quality pastel coloured film mid angle portrait photograph of a beautiful young 2 0 year old ma... (Similarity: 0.85, Concept: prehistoric era)\n",
            "\n",
            "Cluster 3 (11 prompts):\n",
            "  - fallout 7 6 retro futurist illustration art by butcher billy, sticker, colorful, illustration, highl... (Similarity: 0.88, Concept: prehistoric era)\n",
            "  - fallout 7 6 retro futurist illustration art by butcher billy, sticker, colorful, illustration, highl... (Similarity: 0.88, Concept: prehistoric era)\n",
            "  - 1 9 7 9 science fiction focusing on mechwarrior posing at street level in with beautiful scenery. de... (Similarity: 0.89, Concept: prehistoric era)\n",
            "  - fallout 7 6 retro futurist illustration art by butcher billy, sticker, colorful, illustration, highl... (Similarity: 0.88, Concept: prehistoric era)\n",
            "  - fallout 7 6 retro futurist illustration art by butcher billy, sticker, colorful, illustration, highl... (Similarity: 0.88, Concept: prehistoric era)\n",
            "\n",
            "Cluster 4 (17 prompts):\n",
            "  - a magical vintage village on the river | cherry - blossoms | highly detailed | very intricate | sere... (Similarity: 0.82, Concept: prehistoric era)\n",
            "  - a large full armored female knight in a hi-tech botanical world with blue skies | style of donato gi... (Similarity: 0.80, Concept: prehistoric era)\n",
            "  - a dramatic ethereal epic painting of Spider-Gwen | tarot card, art deco, art nouveau, realistic | dr... (Similarity: 0.86, Concept: renaissance period)\n",
            "  - highly detailed oil painting | very intricate | cinematic lighting | black, white and gold color sch... (Similarity: 0.82, Concept: prehistoric era)\n",
            "  - a dramatic ethereal epic symmetrical painting of a handsome!! cowboy in a silvery!!!! ((((golden))))... (Similarity: 0.87, Concept: renaissance period)\n",
            "\n",
            "Cluster 5 (9 prompts):\n",
            "  - üì∑ü´ó... (Similarity: 0.96, Concept: historical figures)\n",
            "  - ü•≤... (Similarity: 0.96, Concept: historical figures)\n",
            "  - üí±üíπ... (Similarity: 0.96, Concept: historical figures)\n",
            "  - üî•üëº... (Similarity: 0.96, Concept: historical figures)\n",
            "  - ü¶äüèìüê∫... (Similarity: 0.96, Concept: historical figures)\n",
            "\n",
            "Cluster 6 (21 prompts):\n",
            "  - ‚ÄúDavid Bowie fish in a fish tank‚Äù... (Similarity: 0.96, Concept: historical battles)\n",
            "  - ‚Äú poster for rambo 2 ‚Äù... (Similarity: 0.96, Concept: historical battles)\n",
            "  - ‚ÄúEditorial photo of two Mormon missionaries winning the Tour de France‚Äù... (Similarity: 0.97, Concept: historical battles)\n",
            "  - ‚Äú human floating in the sky ‚Äù... (Similarity: 0.96, Concept: historical battles)\n",
            "  - ‚Äú1960s BMW M1‚Äù... (Similarity: 0.96, Concept: historical battles)\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataviz"
      ],
      "metadata": {
        "id": "q2_9wZyIhTMd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpR84gfZzzb4"
      },
      "source": [
        "### 1. Visualisation de la distribution des scores de similarit√©\n",
        "\n",
        "Cette cellule permet de visualiser comment les scores de similarit√© sont distribu√©s et d'√©valuer si le seuil choisi (0.6) est appropri√©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84EXA6Vuzzb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97771a65-9d2e-4b4e-cdd4-43151fe3bde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing all 10000 prompts\n",
            "Valid prompts: 9904 out of 10000\n",
            "Generating prompt embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings:   3%|‚ñé         | 9/310 [01:08<28:05,  5.60s/it]  "
          ]
        }
      ],
      "source": [
        "def visualize_similarity_distribution(similarity_scores, threshold=0.6, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Visualise la distribution des scores de similarit√© et marque le seuil utilis√©.\n",
        "\n",
        "    Args:\n",
        "        similarity_scores: Tableau numpy des scores de similarit√©\n",
        "        threshold: Seuil utilis√© pour filtrer les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Histogramme des scores de similarit√©\n",
        "    plt.hist(similarity_scores, bins=50, alpha=0.7, color='steelblue')\n",
        "\n",
        "    # Ligne verticale pour le seuil\n",
        "    plt.axvline(x=threshold, color='red', linestyle='--',\n",
        "                label=f'Seuil ({threshold})')\n",
        "\n",
        "    # Annotations\n",
        "    plt.title('Distribution des scores de similarit√© avec les concepts historiques',\n",
        "              fontsize=14)\n",
        "    plt.xlabel('Score de similarit√©', fontsize=12)\n",
        "    plt.ylabel('Nombre de prompts', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Annotation des statistiques cl√©s\n",
        "    plt.text(0.02, 0.95,\n",
        "             f\"Total: {len(similarity_scores)}\\nHistoriques: {np.sum(similarity_scores > threshold)} ({np.mean(similarity_scores > threshold):.1%})\",\n",
        "             transform=plt.gca().transAxes,\n",
        "             bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'similarity_distribution.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# D'abord, ex√©cutez le pipeline principal pour g√©n√©rer les donn√©es n√©cessaires si pas d√©j√† fait\n",
        "# historical_prompts, prompt_embeddings, max_similarities = process_prompts_for_historical_content(prompts_df)\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_similarity_distribution(max_similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J781NNphzzb5"
      },
      "source": [
        "### 2. Carte de chaleur des similarit√©s entre concepts historiques\n",
        "\n",
        "Cette cellule permet de visualiser comment les concepts historiques sont reli√©s entre eux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0YCcMfazzb6"
      },
      "outputs": [],
      "source": [
        "def visualize_historical_concepts_similarity(historical_concepts, historical_embeddings, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une carte de chaleur montrant les similarit√©s entre concepts historiques.\n",
        "\n",
        "    Args:\n",
        "        historical_concepts: Liste des concepts historiques\n",
        "        historical_embeddings: Embeddings des concepts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Calculer la matrice de similarit√© entre concepts\n",
        "    concept_similarity = cosine_similarity(historical_embeddings)\n",
        "\n",
        "    # Cr√©er une figure de taille appropri√©e\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Cr√©er la heatmap avec seaborn\n",
        "    sns.heatmap(concept_similarity, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",\n",
        "                xticklabels=historical_concepts, yticklabels=historical_concepts)\n",
        "\n",
        "    plt.title(\"Similarit√© entre les concepts historiques\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'historical_concepts_similarity.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_historical_concepts_similarity(historical_concepts, historical_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHMtSy0yzzb6"
      },
      "source": [
        "### 3. Projection UMAP des prompts avec coloration par concept le plus similaire\n",
        "Cette visualisation permet de voir comment les prompts se regroupent naturellement et si les concepts les plus similaires forment des clusters coh√©rents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlMNhI9Nzzb6"
      },
      "outputs": [],
      "source": [
        "def visualize_umap_by_concept(historical_prompts, historical_umap, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Visualise la projection UMAP des prompts, color√©s par concept historique le plus similaire.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques avec leur concept le plus similaire\n",
        "        historical_umap: Coordonn√©es UMAP des prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import os\n",
        "    from matplotlib.colors import ListedColormap\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Obtenir les concepts uniques\n",
        "    unique_concepts = historical_prompts['most_similar_concept'].unique()\n",
        "    n_concepts = len(unique_concepts)\n",
        "\n",
        "    # Cr√©er un mapping des concepts aux indices\n",
        "    concept_to_idx = {concept: i for i, concept in enumerate(unique_concepts)}\n",
        "\n",
        "    # Obtenir un tableau numpy des indices de concepts\n",
        "    concept_indices = np.array([concept_to_idx[concept] for concept in historical_prompts['most_similar_concept']])\n",
        "\n",
        "    # Cr√©er une colormap avec suffisamment de couleurs distinctes\n",
        "    import matplotlib.cm as cm\n",
        "    if n_concepts <= 10:\n",
        "        cmap = ListedColormap(plt.cm.tab10.colors[:n_concepts])\n",
        "    elif n_concepts <= 20:\n",
        "        cmap = ListedColormap(plt.cm.tab20.colors[:n_concepts])\n",
        "    else:\n",
        "        cmap = plt.cm.nipy_spectral\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Scatter plot avec coloration par concept\n",
        "    scatter = plt.scatter(historical_umap[:, 0], historical_umap[:, 1],\n",
        "                         c=concept_indices, cmap=cmap,\n",
        "                         alpha=0.7, s=10)\n",
        "\n",
        "    # Cr√©er une l√©gende explicite\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
        "                              markerfacecolor=cmap(concept_to_idx[concept]),\n",
        "                              markersize=8, label=concept)\n",
        "                       for concept in unique_concepts]\n",
        "\n",
        "    plt.legend(handles=legend_elements, loc='upper right',\n",
        "               bbox_to_anchor=(1.1, 1), ncol=1)\n",
        "\n",
        "    plt.title('Projection UMAP des prompts historiques par concept', fontsize=14)\n",
        "    plt.xlabel('UMAP Dimension 1', fontsize=12)\n",
        "    plt.ylabel('UMAP Dimension 2', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'umap_by_concept.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_umap_by_concept(historical_prompts, historical_umap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpCXtfFezzb6"
      },
      "source": [
        "### 4. Nuage de mots pour chaque cluster\n",
        "\n",
        "Cette visualisation permet d'explorer les termes les plus fr√©quents dans chaque cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HKCYht_zzb7"
      },
      "outputs": [],
      "source": [
        "def generate_cluster_wordclouds(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    G√©n√®re un nuage de mots pour chaque cluster identifi√©.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques avec leurs clusters\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    from wordcloud import WordCloud\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "    # T√©l√©charger les stopwords si n√©cessaire\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Pour chaque cluster\n",
        "    for cluster_id in sorted(historical_prompts['cluster'].unique()):\n",
        "        if cluster_id == -1:  # Ignorer les points de bruit\n",
        "            continue\n",
        "\n",
        "        # Filtrer les prompts de ce cluster\n",
        "        cluster_prompts = historical_prompts[historical_prompts['cluster'] == cluster_id]['prompt']\n",
        "\n",
        "        if len(cluster_prompts) == 0:\n",
        "            continue\n",
        "\n",
        "        # Combiner tous les textes\n",
        "        text = ' '.join(cluster_prompts)\n",
        "\n",
        "        # Cr√©er le nuage de mots\n",
        "        wordcloud = WordCloud(\n",
        "            width=800,\n",
        "            height=400,\n",
        "            background_color='white',\n",
        "            stopwords=stop_words,\n",
        "            max_words=100,\n",
        "            contour_width=3\n",
        "        ).generate(text)\n",
        "\n",
        "        # Afficher et sauvegarder\n",
        "        plt.figure(figsize=(16, 8))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Nuage de mots pour le Cluster {cluster_id} ({len(cluster_prompts)} prompts)',\n",
        "                 fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, f'wordcloud_cluster_{cluster_id}.png'), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"Nuages de mots g√©n√©r√©s pour {len(historical_prompts['cluster'].unique()) - 1} clusters\")\n",
        "\n",
        "# Exemple d'utilisation\n",
        "generate_cluster_wordclouds(historical_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caLeAOPFzzb7"
      },
      "source": [
        "### 5. Distribution des concepts historiques par cluster\n",
        "Cette visualisation montre comment les diff√©rents concepts historiques sont distribu√©s dans les clusters identifi√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW_xK_49zzb8"
      },
      "outputs": [],
      "source": [
        "def visualize_concepts_by_cluster(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une heatmap montrant la distribution des concepts historiques par cluster.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Ignorer les points de bruit (cluster -1) si pr√©sents\n",
        "    if -1 in historical_prompts['cluster'].unique():\n",
        "        df_filtered = historical_prompts[historical_prompts['cluster'] != -1].copy()\n",
        "    else:\n",
        "        df_filtered = historical_prompts.copy()\n",
        "\n",
        "    # Cr√©er une table de contingence\n",
        "    cross_tab = pd.crosstab(\n",
        "        df_filtered['most_similar_concept'],\n",
        "        df_filtered['cluster'],\n",
        "        normalize='index'\n",
        "    )\n",
        "\n",
        "    # Tri pour une meilleure visualisation\n",
        "    # On trie les concepts par cluster dominant\n",
        "    dominant_clusters = cross_tab.idxmax(axis=1)\n",
        "    sorted_concepts = dominant_clusters.sort_values().index\n",
        "    cross_tab = cross_tab.loc[sorted_concepts]\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    sns.heatmap(cross_tab, annot=True, cmap=\"YlGnBu\", fmt='.0%')\n",
        "    plt.title('Distribution des concepts historiques par cluster', fontsize=16)\n",
        "    plt.ylabel('Concept historique', fontsize=14)\n",
        "    plt.xlabel('Cluster', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'concept_cluster_distribution.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "visualize_concepts_by_cluster(historical_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nj9wR-fzzb8"
      },
      "source": [
        "### 6. Analyse des termes les plus communs par concept historique\n",
        "\n",
        "Cette visualisation aide √† comprendre quels termes sont les plus associ√©s √† chaque concept historique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGSJ72tAzzb8"
      },
      "outputs": [],
      "source": [
        "def analyze_terms_by_concept(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Analyse et visualise les termes les plus fr√©quents pour chaque concept historique.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    import nltk\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    from collections import Counter\n",
        "\n",
        "    # T√©l√©charger les ressources NLTK n√©cessaires\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Pour chaque concept historique\n",
        "    for concept in historical_prompts['most_similar_concept'].unique():\n",
        "        # Filtrer les prompts de ce concept\n",
        "        concept_prompts = historical_prompts[historical_prompts['most_similar_concept'] == concept]['prompt']\n",
        "\n",
        "        # Combiner tous les prompts\n",
        "        text = ' '.join(concept_prompts)\n",
        "\n",
        "        # Tokenizer\n",
        "        tokens = word_tokenize(text.lower())\n",
        "\n",
        "        # Filtrer les stopwords et les tokens courts\n",
        "        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words and len(word) > 2]\n",
        "\n",
        "        # Compter les occurrences\n",
        "        word_counts = Counter(filtered_tokens)\n",
        "\n",
        "        # Prendre les N mots les plus fr√©quents\n",
        "        top_n = 20\n",
        "        top_words = word_counts.most_common(top_n)\n",
        "\n",
        "        # Pr√©parer les donn√©es pour le graphique\n",
        "        words = [word for word, count in top_words]\n",
        "        counts = [count for word, count in top_words]\n",
        "\n",
        "        # Cr√©er le graphique\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.barh(words[::-1], counts[::-1], color='steelblue')\n",
        "        plt.xlabel('Fr√©quence')\n",
        "        plt.title(f'Termes les plus fr√©quents pour \"{concept}\" ({len(concept_prompts)} prompts)',\n",
        "                 fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, f'terms_{concept.replace(\" \", \"_\")}.png'), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"Analyse des termes g√©n√©r√©e pour {len(historical_prompts['most_similar_concept'].unique())} concepts\")\n",
        "\n",
        "# Exemple d'utilisation\n",
        "analyze_terms_by_concept(historical_prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kRRe0dgzzb9"
      },
      "source": [
        "### 7. Visualisation interactive avec Plotly\n",
        "\n",
        "Cette cellule cr√©e une visualisation interactive de la projection UMAP qui permet d'explorer les prompts historiques de mani√®re plus interactive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27WS7FxPzzb9"
      },
      "outputs": [],
      "source": [
        "def create_interactive_visualization(historical_prompts, historical_umap, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une visualisation interactive des prompts historiques avec Plotly.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        historical_umap: Coordonn√©es UMAP des prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import plotly.express as px\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Cr√©er un DataFrame pour Plotly\n",
        "    viz_df = pd.DataFrame({\n",
        "        'UMAP1': historical_umap[:, 0],\n",
        "        'UMAP2': historical_umap[:, 1],\n",
        "        'Cluster': historical_prompts['cluster'],\n",
        "        'Concept': historical_prompts['most_similar_concept'],\n",
        "        'Score': historical_prompts['similarity_score'],\n",
        "        'Prompt': historical_prompts['prompt']\n",
        "    })\n",
        "\n",
        "    # Cr√©er la visualisation interactive\n",
        "    fig = px.scatter(\n",
        "        viz_df,\n",
        "        x='UMAP1',\n",
        "        y='UMAP2',\n",
        "        color='Concept',\n",
        "        hover_data=['Prompt', 'Score', 'Cluster'],\n",
        "        opacity=0.7,\n",
        "        title='Exploration interactive des prompts historiques',\n",
        "        template='plotly_white',\n",
        "        color_discrete_sequence=px.colors.qualitative.Bold\n",
        "    )\n",
        "\n",
        "    # Am√©liorer la mise en page\n",
        "    fig.update_layout(\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=-0.2,\n",
        "            xanchor=\"center\",\n",
        "            x=0.5\n",
        "        ),\n",
        "        width=1200,\n",
        "        height=800\n",
        "    )\n",
        "\n",
        "    # Enregistrer en tant que fichier HTML autonome\n",
        "    fig.write_html(os.path.join(output_path, 'interactive_visualization.html'))\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Exemple d'utilisation\n",
        "fig = create_interactive_visualization(historical_prompts, historical_umap)\n",
        "fig.show()  # Afficher dans le notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN3hWpg1zzb-"
      },
      "source": [
        "### 8. R√©seau de co-occurrence de concepts dans les clusters\n",
        "Cette visualisation montre comment les concepts historiques sont li√©s entre eux √† travers leur pr√©sence dans les m√™mes clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwOIg5Qozzb_"
      },
      "outputs": [],
      "source": [
        "def visualize_concept_network(historical_prompts, output_path='./figures/'):\n",
        "    \"\"\"\n",
        "    Cr√©e une visualisation en r√©seau des relations entre concepts historiques\n",
        "    bas√©e sur leur co-occurrence dans les clusters.\n",
        "\n",
        "    Args:\n",
        "        historical_prompts: DataFrame contenant les prompts historiques\n",
        "        output_path: Chemin pour sauvegarder les figures\n",
        "    \"\"\"\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Filtrer pour exclure les points de bruit\n",
        "    if -1 in historical_prompts['cluster'].unique():\n",
        "        df_filtered = historical_prompts[historical_prompts['cluster'] != -1].copy()\n",
        "    else:\n",
        "        df_filtered = historical_prompts.copy()\n",
        "\n",
        "    # Cr√©er un graphe\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Ajouter des n≈ìuds pour chaque concept\n",
        "    concepts = df_filtered['most_similar_concept'].unique()\n",
        "    for concept in concepts:\n",
        "        count = df_filtered[df_filtered['most_similar_concept'] == concept].shape[0]\n",
        "        G.add_node(concept, size=count, count=count)\n",
        "\n",
        "    # Pour chaque cluster, cr√©er des liens entre concepts pr√©sents\n",
        "    for cluster in df_filtered['cluster'].unique():\n",
        "        # Obtenir les concepts dans ce cluster\n",
        "        cluster_concepts = df_filtered[df_filtered['cluster'] == cluster]['most_similar_concept'].unique()\n",
        "\n",
        "        # Cr√©er des liens pour chaque paire de concepts\n",
        "        for i, concept1 in enumerate(cluster_concepts):\n",
        "            for concept2 in cluster_concepts[i+1:]:\n",
        "                # Si le lien existe d√©j√†, augmenter son poids\n",
        "                if G.has_edge(concept1, concept2):\n",
        "                    G[concept1][concept2]['weight'] += 1\n",
        "                else:\n",
        "                    G.add_edge(concept1, concept2, weight=1)\n",
        "\n",
        "    # Taille des n≈ìuds bas√©e sur la fr√©quence\n",
        "    node_sizes = [G.nodes[node]['size'] * 20 for node in G.nodes]\n",
        "\n",
        "    # √âpaisseur des liens bas√©e sur les poids\n",
        "    edge_weights = [G[u][v]['weight'] * 0.5 for u, v in G.edges]\n",
        "\n",
        "    # Positionner les n≈ìuds\n",
        "    pos = nx.spring_layout(G, seed=42, k=0.3)\n",
        "\n",
        "    plt.figure(figsize=(14, 12))\n",
        "\n",
        "    # Dessiner les n≈ìuds\n",
        "    nx.draw_networkx_nodes(G, pos,\n",
        "                          node_size=node_sizes,\n",
        "                          node_color='skyblue',\n",
        "                          alpha=0.8)\n",
        "\n",
        "    # Dessiner les liens\n",
        "    nx.draw_networkx_edges(G, pos,\n",
        "                          width=edge_weights,\n",
        "                          alpha=0.5,\n",
        "                          edge_color='gray')\n",
        "\n",
        "    # Ajouter les √©tiquettes\n",
        "    nx.draw_networkx_labels(G, pos, font_size=10, font_family='sans-serif')\n",
        "\n",
        "    plt.title('R√©seau de co-occurrence des concepts historiques', fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'concept_network.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return G\n",
        "\n",
        "# Exemple d'utilisation\n",
        "concept_network = visualize_concept_network(historical_prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byOi5gGezzb_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "citation-manager": {
      "items": {}
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.11 (negotiating_past)",
      "language": "python",
      "name": "negotiating_past"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}